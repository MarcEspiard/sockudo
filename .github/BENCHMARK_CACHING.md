# GitHub Actions Benchmark Caching Strategy

This document outlines the comprehensive caching strategy implemented for the Sockudo benchmark workflow to dramatically improve CI/CD performance.

## ðŸš€ Caching Layers Implemented

### 1. **Docker Layer Caching**
- **What**: Caches Docker build layers across workflow runs
- **Key**: Based on Cargo.lock, Cargo.toml, and Dockerfile hashes
- **Benefit**: ~5-10 minute faster Docker builds on cache hits
- **Location**: `/tmp/.buildx-cache`

### 2. **Node.js Dependency Caching**
- **What**: Caches npm packages for benchmark scripts
- **Key**: Based on package-lock.json hash
- **Benefit**: ~30-60 seconds faster npm installs
- **Mechanism**: Built-in GitHub Actions cache with `cache: 'npm'`

### 3. **k6 Binary Caching**
- **What**: Caches the k6 load testing tool binary
- **Key**: Based on workflow file hash (rarely changes)
- **Benefit**: ~2-3 minutes faster k6 installation
- **Location**: `/usr/bin/k6`

### 4. **Rust Dependencies (Future)**
- **Potential**: Could add Cargo registry caching for even faster builds
- **Not implemented yet**: Docker layer caching already covers compiled artifacts

## ðŸ“Š Performance Impact

### Before Caching:
- Docker build: **8-12 minutes** (Rust compilation from scratch)
- npm install: **30-60 seconds** (download all packages)
- k6 install: **2-3 minutes** (APT update + install)
- **Total overhead: ~10-15 minutes per job**

### After Caching:
- Docker build: **30-90 seconds** (cache hit)
- npm install: **5-10 seconds** (cache hit)
- k6 install: **0 seconds** (cache hit)
- **Total overhead: ~1-2 minutes per job**

### Net Improvement:
- **~8-13 minutes faster per benchmark job**
- **~24-39 minutes faster for full benchmark suite** (3 parallel jobs)
- **~85% reduction in setup time**

## ðŸ”„ Cache Keys and Strategy

### Cache Key Composition:
```yaml
# Docker layers
key: ${{ runner.os }}-buildx-sockudo-build-${{ hashFiles('**/Cargo.lock', '**/Cargo.toml', 'Dockerfile') }}

# Node.js dependencies  
key: node-modules-${{ hashFiles('**/package-lock.json') }}

# k6 binary
key: ${{ runner.os }}-k6-${{ hashFiles('.github/workflows/benchmark.yml') }}
```

### Cache Invalidation:
- **Docker**: When Rust code, dependencies, or Dockerfile changes
- **Node.js**: When package-lock.json changes (new/updated dependencies)
- **k6**: When benchmark workflow changes (rarely)

## ðŸ›  Implementation Details

### Docker BuildKit Cache:
```yaml
- name: Cache Docker layers
  uses: actions/cache@v4
  with:
    path: /tmp/.buildx-cache
    key: ${{ runner.os }}-buildx-${{ needs.prepare.outputs.cache_key }}
    restore-keys: |
      ${{ runner.os }}-buildx-
```

### Node.js Cache:
```yaml
- name: Install Node.js
  uses: actions/setup-node@v4
  with:
    node-version: '18'
    cache: 'npm'  # Automatic caching
    cache-dependency-path: 'test/benchmarks/package-lock.json'
```

### k6 Installation Cache:
```yaml
- name: Cache k6 installation
  id: cache-k6
  uses: actions/cache@v4
  with:
    path: /usr/bin/k6
    key: ${{ runner.os }}-k6-${{ hashFiles('.github/workflows/benchmark.yml') }}

- name: Install k6
  if: steps.cache-k6.outputs.cache-hit != 'true'
  run: |
    # APT installation commands
```

## ðŸ“ˆ Cache Hit Ratios (Expected)

Based on typical development patterns:

- **Docker cache hit**: ~70-80% (code changes more often than deps)
- **Node.js cache hit**: ~90-95% (benchmark deps rarely change)
- **k6 cache hit**: ~98-99% (workflow rarely changes)

## ðŸ”§ Maintenance

### Cache Management:
- GitHub Actions automatically expires caches after 7 days of no access
- Cache size limits: 10GB per repository
- Older caches are automatically evicted when limit is reached

### Monitoring:
- Check workflow run times to verify cache effectiveness
- Monitor cache hit rates in workflow logs
- Invalidate caches manually if needed via GitHub UI

## ðŸŽ¯ Future Optimizations

1. **Multi-stage Docker builds**: Further optimize Docker layer caching
2. **Registry cache**: Use Docker registry for even better cache persistence
3. **Parallel builds**: Cache and build different components in parallel
4. **Baseline caching**: Cache benchmark baseline results for comparison

This caching strategy ensures that benchmark workflows run efficiently while maintaining accuracy and reliability of performance measurements.